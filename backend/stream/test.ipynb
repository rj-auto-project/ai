{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from datetime import datetime, timedelta\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import torch\n",
    "from db_sql import predict_count, resize_image\n",
    "import tensorflow as tf\n",
    "from timmML_025.models.factory import create_model\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from color_detection import format_output, crop_and_classify\n",
    "import joblib\n",
    "\n",
    "# import cProfile\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO(\"/home/devendra/ai-camera/backend/stream/best.pt\")\n",
    "model.to(device)\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=\"\", database=\"logs\"\n",
    ")\n",
    "\n",
    "\n",
    "# Signal handler function\n",
    "def signal_handler(sig, frame):\n",
    "    print(\"Termination signal received. Releasing resources...\")\n",
    "    if \"video_writer\" in globals() and video_writer is not None:\n",
    "        video_writer.release()\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "# Register the signal handler\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "signal.signal(signal.SIGTERM, signal_handler)\n",
    "\n",
    "\n",
    "def get_creation_time(file_path):\n",
    "    # Get the file creation time\n",
    "    if os.name == \"nt\":  # Windows\n",
    "        creation_time = os.path.getctime(file_path)\n",
    "    else:\n",
    "        stat = os.stat(file_path)\n",
    "        # try:\n",
    "        #     creation_time = stat.st_birthtime\n",
    "        # except AttributeError:\n",
    "        #     # For Linux, if birth time is not available, fall back to the last metadata change time\n",
    "        creation_time = stat.st_mtime\n",
    "\n",
    "    return datetime.fromtimestamp(creation_time)\n",
    "\n",
    "\n",
    "def get_video_frame_time(video_path, frame_number):\n",
    "    # Get the start time from the file creation time\n",
    "    start_time = get_creation_time(video_path)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return None\n",
    "\n",
    "    # Get the frame rate of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0:\n",
    "        print(\"Error: Could not retrieve frame rate.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate the elapsed time since the start of the video\n",
    "    elapsed_time_seconds = frame_number / fps\n",
    "    elapsed_time = timedelta(seconds=elapsed_time_seconds)\n",
    "\n",
    "    # Calculate the actual time of the frame\n",
    "    actual_time = start_time + elapsed_time\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    return actual_time\n",
    "\n",
    "\n",
    "\n",
    "def insert_into_table(\n",
    "    camera_id,\n",
    "    camera_ip,\n",
    "    timestamp,\n",
    "    box_coords,\n",
    "    detection_class,\n",
    "    track_id,\n",
    "    class_confidence,\n",
    "    metadata,\n",
    "):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\", user=\"root\", password=\"\", database=\"logs\"\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "            insert_query = f\"INSERT INTO detection_logs (camera_id, camera_ip, timestamp, box_coords, detection_class, track_id, class_confidence, metadata) VALUES ('{camera_id}' ,'{camera_ip}', '{timestamp}', '{box_coords}', '{detection_class}', '{track_id}', '{class_confidence}', '{metadata}');\"\n",
    "            cursor.execute(insert_query)\n",
    "            connection.commit()\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "def generate_custom_string(cam_ip, track_id):\n",
    "    # Replace dots in the camera IP with underscores\n",
    "    cam_ip = cam_ip.replace(\".\", \"_\")\n",
    "\n",
    "    # Get the current timestamp\n",
    "    current_timestamp = int(time.time())\n",
    "\n",
    "    # Generate a random string of 4 characters and 4 digits mixed\n",
    "    random_mix = \"\".join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "\n",
    "    # Combine all parts into the final string\n",
    "    custom_string = f\"{random_mix}_{track_id}_{current_timestamp}_{cam_ip}\"\n",
    "\n",
    "    return custom_string\n",
    "\n",
    "\n",
    "# Function to detect and display objects in video\n",
    "def detect_and_display(video_path, output_path, cam_id, cam_ip):\n",
    "    # Set up the crowd count model\n",
    "    global video_writer\n",
    "\n",
    "    crowd_count_model = create_model(\"efficientnet_lite0\")\n",
    "    PATH_model = \"/home/devendra/ai-camera/backend/stream/student_025.pt\"\n",
    "    MEAN_STD = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    crowd_count_model.load_state_dict(torch.load(PATH_model, map_location=device))\n",
    "    crowd_count_model.to(device)\n",
    "    crowd_count_model.eval()\n",
    "    img_transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(MEAN_STD[0], MEAN_STD[1])]\n",
    "    )\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    width, height = 640, 480\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "    crowd_count = 0\n",
    "    crowd_confidence = 0.0\n",
    "\n",
    "    custom_track_ids = {}\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, ori_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_count += 1\n",
    "        vehicle_count = 0\n",
    "        if frame_count == 60:\n",
    "            break\n",
    "        frame = cv2.resize(ori_frame, (width, height))\n",
    "\n",
    "        results = model.track(frame, persist=True, device=device)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            scores = result.boxes.conf.cpu().numpy()\n",
    "            classes = result.boxes.cls.cpu().numpy()\n",
    "            # set1 = set(classes)\n",
    "            # print(set1)\n",
    "            # set2 = set([0,1,2,3,4,5,6])\n",
    "            # intersection  = set1.intersection(set2)\n",
    "            # vehicle_count = len(intersection)\n",
    "            track_ids = (\n",
    "                result.boxes.id.int().cpu().tolist()\n",
    "                if result.boxes.id is not None\n",
    "                else []\n",
    "            )\n",
    "\n",
    "            for box, score, cls, track_id in zip(boxes, scores, classes, track_ids):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                label = model.names[int(cls)]\n",
    "                class_confidence = score\n",
    "                if track_id not in custom_track_ids:\n",
    "                    custom_track_ids[track_id] = generate_custom_string(\n",
    "                        cam_ip, track_id\n",
    "                    )\n",
    "\n",
    "                # custom unique tracking id\n",
    "                custom_id = custom_track_ids[track_id]\n",
    "\n",
    "                # vehicle count\n",
    "                if label in [\n",
    "                    \"auto\",\n",
    "                    \"motorbike\",\n",
    "                    \"bike-rider\",\n",
    "                    \"car\",\n",
    "                    \"suv\",\n",
    "                    \"hatchback\",\n",
    "                    \"sedan\",\n",
    "                    \"scooty-rider\",\n",
    "                    \"scooty\",\n",
    "                    \"bus\",\n",
    "                    \"truck\",\n",
    "                    \"tractor\",\n",
    "                    \"loader\",\n",
    "                ]:\n",
    "                    vehicle_count += 1\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"{label}\",\n",
    "                    (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.2,\n",
    "                    (0, 255, 0),\n",
    "                    1,\n",
    "                )\n",
    "                cropped_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                # Insert into the database\n",
    "                at = get_video_frame_time(video_path, frame_count)\n",
    "                classifier = joblib.load(\n",
    "                    \"/home/devendra/ai-camera/backend/stream/pixel_classifier.joblib\"\n",
    "                )\n",
    "                label_encoder = joblib.load(\n",
    "                    \"/home/devendra/ai-camera/backend/stream/label_encoder.joblib\"\n",
    "                )\n",
    "\n",
    "                output = crop_and_classify(\n",
    "                    cropped_img, label, classifier, label_encoder\n",
    "                )\n",
    "                metadata = format_output(output)\n",
    "                metadata = \"\"\"{\n",
    "                    \"upper\": {\"black\": 0.30, \"red\": 0.23, \"charcoal\": 0.20},\n",
    "                    \"lower\": {\"black\": 0.35, \"charcoal\": 0.31, \"red\": 0.26},\n",
    "                }\"\"\"\n",
    "                insert_into_table(\n",
    "                    camera_id=cam_id,\n",
    "                    camera_ip=cam_ip,\n",
    "                    # timestamp=at,\n",
    "                    timestamp=\"2024-07-07 12:00:00\",\n",
    "                    box_coords=[x1, y1, x2, y2],\n",
    "                    detection_class=label,\n",
    "                    track_id=custom_id,\n",
    "                    class_confidence=class_confidence,\n",
    "                    metadata=metadata,\n",
    "                )\n",
    "\n",
    "        # Crowd count processing\n",
    "        if frame_count % 5 == 0:\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(rgb_frame)\n",
    "            img = resize_image(img)\n",
    "            crowd_count, crowd_confidence = predict_count(img, crowd_count_model)\n",
    "\n",
    "            # Insert crowd count into the database\n",
    "            # at = get_video_frame_time(video_path, frame_count)\n",
    "            crowd_insert_into_table(\n",
    "                camera_id=cam_id,\n",
    "                camera_ip=cam_ip,\n",
    "                # timestamp=at,\n",
    "                timestamp=\"2024-07-07 12:00:00\",\n",
    "                crowd_count=crowd_count,\n",
    "                crowd_count_confidence_score=crowd_confidence,\n",
    "            )\n",
    "            vehicle_count_insert_into_table(\n",
    "                camera_id=cam_id,\n",
    "                camera_ip=cam_ip,\n",
    "                timestamp=\"2024-07-07 12:00:00\",\n",
    "                # timestamp=at,\n",
    "                vehicle_count=vehicle_count,\n",
    "            )\n",
    "\n",
    "        # # Overlay FPS and crowd count on the frame\n",
    "        fps_text = f\"FPS: {fps}\"\n",
    "        crowd_count_text = f\"Crowd Count: {crowd_count}\"\n",
    "        cv2.putText(\n",
    "            frame, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            crowd_count_text,\n",
    "            (10, 50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            1,\n",
    "        )\n",
    "        vehicle_count_text = f\"Vehicle Count : {vehicle_count}\"\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            str(vehicle_count_text),\n",
    "            (450, 30),\n",
    "            cv2.FONT_HERSHEY_DUPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        video_writer.write(frame)\n",
    "        # cv2.imshow(\"test\", frame)\n",
    "    cap.release()\n",
    "    if video_writer is not None:\n",
    "        video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def crowd_insert_into_table(\n",
    "    camera_id, camera_ip, timestamp, crowd_count, crowd_count_confidence_score\n",
    "):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\", user=\"root\", password=\"\", database=\"logs\"\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "            insert_query = f\"INSERT INTO crowd_count (camera_id, camera_ip, timestamp, crowd_count, crowd_count_confidence_score) VALUES ('{camera_id}', '{camera_ip}',' {timestamp}',' {crowd_count}', '{crowd_count_confidence_score}')\"\n",
    "            cursor.execute(insert_query)\n",
    "            connection.commit()\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "def vehicle_count_insert_into_table(camera_id, camera_ip, timestamp, vehicle_count):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\", user=\"root\", password=\"\", database=\"logs\"\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "            insert_query = f\"INSERT INTO vehicle_count_logs (camera_id, camera_ip, timestamp, vehicle_count) VALUES ('{camera_id}', '{camera_ip}',' {timestamp}',' {vehicle_count}')\"\n",
    "            cursor.execute(insert_query)\n",
    "            connection.commit()\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "def run_multiprocesses():\n",
    "    # multiprocessing.set_start_method(\"spawn\",force=True)\n",
    "    cam_id1 = \"6\"\n",
    "    cam_id2 = \"2\"\n",
    "    cam_id3 = \"3\"\n",
    "    cam_id4 = \"4\"\n",
    "\n",
    "    cam_ip1 = \"171.31.4.79\"\n",
    "    cam_ip2 = \"171.31.4.36\"\n",
    "    cam_ip3 = \"171.31.4.47\"\n",
    "    cam_ip4 = \"171.31.4.57\"\n",
    "    detect_and_display(\n",
    "        \"/home/devendra/data/171.31.4.79.MKV\",\n",
    "        \"/home/devendra/data/output/171.31.4.79_output.mp4\",\n",
    "        cam_id1,\n",
    "        cam_ip1,\n",
    "    )\n",
    "    # p1 = multiprocessing.Process(\n",
    "    #     target=detect_and_display,\n",
    "    #     args=(\n",
    "    #          \"/home/devendra/data/171.31.4.79.MKV\",\n",
    "    #         \"/home/devendra/data/output/171.31.4.79_output.mp4\",\n",
    "    #         cam_id1,\n",
    "    #         cam_ip1,\n",
    "    #     ),\n",
    "    # )\n",
    "    # p2 = multiprocessing.Process(\n",
    "    #     target=detect_and_display,\n",
    "    #     args=(\n",
    "    #         \"/home/devendra/data/171.31.4.36.MKV\",\n",
    "    #         \"/home/devendra/data/output/171.31.4.36_output.mp4\",\n",
    "    #         cam_id2,\n",
    "    #         cam_ip2,\n",
    "    #     ),\n",
    "    # )\n",
    "    # p3 = multiprocessing.Process(\n",
    "    #     target=detect_and_display,\n",
    "    #     args=(\n",
    "    #         \"/home/devendra/data/171.31.4.47.MKV\",\n",
    "    #         \"/home/devendra/data/output/171.31.4.47_output.mp4\",\n",
    "    #         cam_id3,\n",
    "    #         cam_ip3,\n",
    "    #     ),\n",
    "    # )\n",
    "    # p4 = multiprocessing.Process(\n",
    "    #     target=detect_and_display,\n",
    "    #     args=(\n",
    "    #         \"/home/devendra/data/171.31.4.57.MKV\",\n",
    "    #         \"/home/devendra/data/output/171.31.4.57_output.mp4\",\n",
    "    #         cam_id4,\n",
    "    #         cam_ip4,\n",
    "    #     ),\n",
    "    # )\n",
    "\n",
    "    # p1.start()\n",
    "    # p2.start()\n",
    "    # p3.start()\n",
    "    # p4.start()\n",
    "\n",
    "    # p1.join()\n",
    "    # p2.join()\n",
    "    # p3.join()\n",
    "    # p4.join()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import cProfile, pstats\n",
    "    import io\n",
    "    from pstats import SortKey\n",
    "\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    # cProfile.run('run_multiprocesses()')\n",
    "    t1 = time.time()\n",
    "    cam_id1 = \"6\"\n",
    "    cam_ip1 = \"171.31.4.79\"\n",
    "    detect_and_display(\n",
    "        \"/home/devendra/data/171.31.4.79.MKV\",\n",
    "        \"/home/devendra/data/output/171.31.4.79_output.mp4\",\n",
    "        cam_id1,\n",
    "        cam_ip1,\n",
    "    )\n",
    "    t2 = time.time()\n",
    "    print(t1-t2)\n",
    "    profiler.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = SortKey.CUMULATIVE\n",
    "    stats = pstats.Stats(profiler, stream=s).sort_stats(sortby)\n",
    "    stats.print_stats()\n",
    "    stats.strip_dirs()\n",
    "    stats.print_stats()\n",
    "    # Save the profiling results to a file\n",
    "    profiler.dump_stats(\n",
    "        \"/home/devendra/ai-camera/backend/stream/profiling_results.prof\"\n",
    "    )\n",
    "\n",
    "    # Use snakeviz to visualize the results\n",
    "    import os\n",
    "\n",
    "    os.system(\"snakeviz /home/devendra/ai-camera/backend/stream/profiling_results.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from module import crowd_count_on_frame,insert_into_table,crowd_insert_into_table,generate_custom_string,do_threading\n",
    "from module import do_threading\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = time.time()\n",
    "# generate_custom_string(\"23.45.67.89\",\"ABGC25563\")\n",
    "# insert_into_table()\n",
    "# crowd_insert_into_table()\n",
    "# print(crowd_count_on_frame(cv2.imread(\"/home/annone/ai-camera/backend/stream_test/4.png\")))\n",
    "do_threading()\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read coordinates from the file\n",
    "with open('/home/annone/ai-camera/vid1_frame_87.txt', 'r') as file:\n",
    "    data = file.read().strip().split()\n",
    "    coords = list(map(float, data[1:]))\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 1920,1080\n",
    "\n",
    "# Function to denormalize coordinates\n",
    "def denormalize_coords(coords, img_width, img_height):\n",
    "    denormalized = []\n",
    "    for i in range(0, len(coords), 2):\n",
    "        x = coords[i] * img_width\n",
    "        y = coords[i + 1] * img_height\n",
    "        denormalized.append((x, y))\n",
    "    return denormalized\n",
    "\n",
    "# Denormalize coordinates\n",
    "denormalized_coords = denormalize_coords(coords, img_width, img_height)\n",
    "\n",
    "# Load the image (replace 'image_path' with the actual image path)\n",
    "image_path = '/home/annone/ai-camera/vid1_frame_87.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Create a mask\n",
    "mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "\n",
    "# Fill the polygon in the mask\n",
    "pts = np.array(denormalized_coords, np.int32)\n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "cv2.fillPoly(mask, [pts], 255)\n",
    "\n",
    "# Create a new image with an alpha channel (4 channels)\n",
    "polygon_image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "polygon_image[:, :, 3] = mask\n",
    "\n",
    "# Crop to the bounding box of the polygon\n",
    "x, y, w, h = cv2.boundingRect(pts)\n",
    "cropped_polygon_image = polygon_image[y:y+h, x:x+w]\n",
    "\n",
    "# Save the cropped polygon image (replace 'cropped_polygon_image_path' with the desired path)\n",
    "cropped_polygon_image_path = 'cropped_polygon_image.png'\n",
    "cv2.imwrite(cropped_polygon_image_path, cropped_polygon_image)\n",
    "\n",
    "# Display the cropped polygon image\n",
    "cv2.imshow('Cropped Polygon Image', cropped_polygon_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from color_detection import format_output, crop_and_classify\n",
    "import joblib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "t1 = time.time()\n",
    "classifier = joblib.load(\n",
    "                    \"/home/annone/ai-camera/backend/stream_test/pixel_classifier.joblib\"\n",
    ")\n",
    "label_encoder = joblib.load(\n",
    "                    \"/home/annone/ai-camera/backend/stream_test/label_encoder.joblib\")\n",
    "output = crop_and_classify(\n",
    "                    \"/home/annone/ai-camera/backend/stream/cropped_polygon_image.png\", \"bike-rider\", classifier, label_encoder\n",
    ")\n",
    "print(output)\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    return image\n",
    "\n",
    "def find_dominant_colors(image_path, k=3):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(image)\n",
    "    colors = kmeans.cluster_centers_\n",
    "    counts = np.bincount(kmeans.labels_)\n",
    "\n",
    "    # Order the colors by the number of pixels assigned\n",
    "    sorted_indices = np.argsort(counts)[::-1]\n",
    "    dominant_colors = colors[sorted_indices]\n",
    "    return dominant_colors.astype(int)\n",
    "\n",
    "def plot_colors(colors):\n",
    "    # Create an image to display the colors\n",
    "    color_image = np.zeros((50, 300, 3), dtype=\"uint8\")\n",
    "\n",
    "    start = 0\n",
    "    for i, color in enumerate(colors):\n",
    "        end = start + (300 // len(colors))\n",
    "        cv2.rectangle(color_image, (start, 0), (end, 50), color.tolist(), -1)\n",
    "        start = end\n",
    "\n",
    "    # Display the color image\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(color_image)\n",
    "    plt.show()\n",
    "\n",
    "def main(image_path):\n",
    "    # image = load_image(image_path)\n",
    "    # processed_image = preprocess_image(image_path)\n",
    "    dominant_colors = find_dominant_colors(image_path, k=3)\n",
    "    plot_colors(dominant_colors)\n",
    "    print(\"Top 3 dominant colors (RGB):\", dominant_colors)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"/home/annone/ai-camera/eee.png\"  # Replace with your image path\n",
    "    main(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# r.set('count', 89)\n",
    "count = r.get('test')\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Function to get all keys and their values\n",
    "def get_all_data():\n",
    "    # Use SCAN to get all keys (more efficient than KEYS for large datasets)\n",
    "    cursor = '0'\n",
    "    all_keys = []\n",
    "\n",
    "    while cursor != 0:\n",
    "        cursor, keys = r.scan(cursor=cursor)\n",
    "        all_keys.extend(keys)\n",
    "\n",
    "    # Dictionary to hold all key-value pairs\n",
    "    all_data = {}\n",
    "\n",
    "    # Get the value for each key\n",
    "    for key in all_keys:\n",
    "        key_type = r.type(key).decode('utf-8')\n",
    "        \n",
    "        if key_type == 'string':\n",
    "            value = r.get(key)\n",
    "            try:\n",
    "                all_data[key.decode('utf-8')] = value.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                all_data[key.decode('utf-8')] = value\n",
    "        elif key_type == 'hash':\n",
    "            hash_data = r.hgetall(key)\n",
    "            decoded_hash_data = {k.decode('utf-8'): v.decode('utf-8') for k, v in hash_data.items()}\n",
    "            all_data[key.decode('utf-8')] = decoded_hash_data\n",
    "        elif key_type == 'list':\n",
    "            list_data = r.lrange(key, 0, -1)\n",
    "            decoded_list_data = [item.decode('utf-8') for item in list_data]\n",
    "            all_data[key.decode('utf-8')] = decoded_list_data\n",
    "        elif key_type == 'set':\n",
    "            set_data = r.smembers(key)\n",
    "            decoded_set_data = {item.decode('utf-8') for item in set_data}\n",
    "            all_data[key.decode('utf-8')] = decoded_set_data\n",
    "        elif key_type == 'zset':\n",
    "            zset_data = r.zrange(key, 0, -1, withscores=True)\n",
    "            decoded_zset_data = [(item[0].decode('utf-8'), item[1]) for item in zset_data]\n",
    "            all_data[key.decode('utf-8')] = decoded_zset_data\n",
    "        else:\n",
    "            all_data[key.decode('utf-8')] = f'Unsupported data type: {key_type}'\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    data = get_all_data()\n",
    "    for key, value in data.items():\n",
    "        print(f\"Key: {key}, Value: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dbname': 'logs', 'user': 'root', 'password': 'team123', 'host': '34.47.148.81', 'port': '8080'}\n",
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annone/ai-camera/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from  PIL import Image\n",
    "import PIL.Image\n",
    "import redis\n",
    "import PIL\n",
    "import os\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from module import k_mean_color_detection\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import random\n",
    "from module import  process_raw_d_logs, process_d_logs, process_raw_cc_logs, process_cc_logs\n",
    "\n",
    "# Connect to the Redis server\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "def clear_redis_database():\n",
    "    r.flushdb()\n",
    "    print(\"Redis database cleared.\")\n",
    "\n",
    "# Function to store string data with key namespacing\n",
    "def store_string_with_namespace(serial_number, constant_string, value):\n",
    "    full_key = f\"{serial_number}:{constant_string}\"\n",
    "    r.set(full_key, value)\n",
    "    print(f\"Stored {full_key} -> {value}\")\n",
    "\n",
    "# Function to retrieve all data matching the constant part of the key\n",
    "def retrieve_keys(constant_string):\n",
    "    matching_keys = r.keys(f\"*:{constant_string}\")\n",
    "    results = {}\n",
    "    for key in matching_keys:\n",
    "        value = r.get(key)\n",
    "        if value:\n",
    "            decoded_key = key.decode()\n",
    "            decoded_value = value.decode()\n",
    "            results[decoded_key] = decoded_value\n",
    "            # r.delete(decoded_key)\n",
    "            # print(results)\n",
    "            # r.delete(key)  # Delete the key after retrieving the value\n",
    "            # print(f\"Retrieved and deleted {decoded_key} -> {decoded_value}\")\n",
    "    return results\n",
    "\n",
    "def process_raw_d_logs(constant_string):\n",
    "    while True:\n",
    "        matching_keys = r.keys(f\"*:{constant_string}\")\n",
    "        # print(matching_keys)\n",
    "        for key in matching_keys:\n",
    "            value = r.get(key)\n",
    "            decode_key = key.decode()\n",
    "            decode_value = value.decode().split(\"|\")\n",
    "            track_id = decode_value[5]\n",
    "            image_path = decode_value[7]\n",
    "            try:\n",
    "                image = cv2.imread(f\"/home/annone/ai-camera/backend/stream/temp/{image_path}\")\n",
    "                image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "                aa = k_mean_color_detection(image)\n",
    "                decode_value[7]  = aa\n",
    "                r.set(f\"{track_id}_{random.randint(0,9999)}:d_log\",\"|\".join(decode_value))\n",
    "                os.remove(f\"/home/annone/ai-camera/backend/stream/temp/{image_path}\")\n",
    "                r.delete(decode_key)\n",
    "            except:\n",
    "                # print(\"excepted\")\n",
    "                continue\n",
    "            # show_rgb_colors(aa,image)\n",
    "            # print(decode_value)\n",
    "            \n",
    "from db import Database\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# def process_d_logs(constant_string):\n",
    "#     conn = Database.get_connection()\n",
    "#     cursor = conn.cursor()\n",
    "#     batch = []\n",
    "#     while True:\n",
    "#         matching_keys = r.keys(f\"*:{constant_string}\")\n",
    "#         for key in matching_keys:\n",
    "#             value = r.get(key)\n",
    "#             decode_key = key.decode()\n",
    "#             decode_value = value.decode().split(\"|\")\n",
    "#             batch.append(tuple(decode_value))\n",
    "#         if len(batch) > 0:\n",
    "#             query = 'INSERT INTO \"DetectionLog\" (\"cameraId\", \"camera_ip\", \"timestamp\", \"boxCoords\", \"detectionClass\", \"trackId\", \"classConfidence\", \"metadata\") VALUES %s;'\n",
    "#             execute_values(cursor, query, batch)\n",
    "#             conn.commit()\n",
    "#             cursor.close()\n",
    "#             conn.close()\n",
    "#             batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_keys(\"d_log\")\n",
    "# clear_redis_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_raw_d_logs(auto_loop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_keys(\"cc_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_d_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md_log\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai-camera/backend/stream/module.py:227\u001b[0m, in \u001b[0;36mprocess_d_logs\u001b[0;34m(auto_loop)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_loop \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_d_logs(\"d_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redis database cleared.\n"
     ]
    }
   ],
   "source": [
    "clear_redis_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dbname': 'logs', 'user': 'root', 'password': 'team123', 'host': '34.47.148.81', 'port': '8080'}\n",
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annone/ai-camera/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from db import Database\n",
    "from module import  process_raw_d_logs, process_d_logs, process_raw_cc_logs, process_cc_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('127.0.0.1', '2024-08-23 14:20:18.151860', '4', '1.0'), ('127.0.0.1', '2024-08-23 14:20:22.718332', '0', '1.0'), ('127.0.0.1', '2024-08-23 14:20:24.544853', '1', '1.0'), ('127.0.0.1', '2024-08-23 14:20:28.732350', '2', '1.0'), ('127.0.0.1', '2024-08-23 14:20:33.044650', '1', '1.0'), ('127.0.0.1', '2024-08-23 14:20:39.164609', '0', '1.0'), ('127.0.0.1', '2024-08-23 14:20:34.903171', '2', '1.0'), ('127.0.0.1', '2024-08-23 14:20:20.403214', '1', '1.0'), ('127.0.0.1', '2024-08-23 14:20:26.963614', '1', '1.0'), ('127.0.0.1', '2024-08-23 14:20:37.298390', '1', '1.0'), ('127.0.0.1', '2024-08-23 14:20:15.927987', '9', '1.0'), ('127.0.0.1', '2024-08-23 14:20:31.086890', '1', '1.0')]\n",
      "one done\n"
     ]
    }
   ],
   "source": [
    "process_cc_logs(auto_loop=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
