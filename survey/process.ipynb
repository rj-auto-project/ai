{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### program settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dbname': 'dev_db', 'user': 'postgres', 'password': 'argus123', 'host': '34.47.226.185', 'port': '8080', 'sslmode': 'disable'}\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from sort.sort import Sort  # Ensure you have SORT installed or use your custom tracking implementation\n",
    "import numpy as np\n",
    "from db import Database\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('/home/annone/ai/survey/data/weights/best.pt')  # Replace with the path to your .pt file\n",
    "\n",
    "# Input video file (replace with your video path or set to 0 for webcam)\n",
    "input_video_path = '/home/annone/ai/survey/data/VID_20241115_155636.mp4'  # Replace with the input video file path\n",
    "output_video_path = '/home/annone/ai/survey/data/video3.mp4'  # Replace with the output video file path\n",
    "json_data_file = \"/home/annone/ai/survey/temp_database_test.json\"\n",
    "class_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "a = [1,2]\n",
    "print(json.dumps(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to DB function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Database.get_connection()\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_postgres(thumbnail, class_name, survey_id, geo_coords, distance ):\n",
    "    query = \"\"\"\n",
    "    INSERT INTO \"SurveyReport\" (\"thumbnail\", \"className\", \"surveyId\", \"location\", \"distance\")\n",
    "    VALUES (%s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = (f\"{thumbnail}\", f\"{class_name}\", f\"{survey_id}\", f\"{geo_coords}\", f\"{distance}\")\n",
    "        cursor.execute(query, data)\n",
    "        conn.commit()\n",
    "        print(\"Data saved successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data: {e}\")\n",
    "\n",
    "def log_into_json(file_path=json_data_file, new_data=\"\"):\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as json_file:\n",
    "                try:\n",
    "                    existing_data = json.load(json_file)\n",
    "                except json.JSONDecodeError:\n",
    "                    existing_data = []\n",
    "        else:\n",
    "            existing_data = []\n",
    "        if isinstance(existing_data, list):\n",
    "            existing_data.append(new_data)\n",
    "        else:\n",
    "            raise TypeError(\"Existing JSON data must be a list to append new data.\")\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(existing_data, json_file, indent=4)\n",
    "        print(f\"Data successfully appended to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error appending to JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annone/ai/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 (no detections), 60.4ms\n",
      "Speed: 4.1ms preprocess, 60.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 3.0ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 4.2ms preprocess, 27.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.2ms\n",
      "Speed: 2.9ms preprocess, 24.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.7ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.7ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.8ms\n",
      "Speed: 1.5ms preprocess, 27.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.4ms preprocess, 23.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.9ms\n",
      "Speed: 3.8ms preprocess, 32.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 23.9ms\n",
      "Speed: 2.2ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 28.5ms\n",
      "Speed: 2.4ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.4ms preprocess, 26.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 24.0ms\n",
      "Speed: 2.1ms preprocess, 24.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 fault-manhole, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 1 drainage, 23.7ms\n",
      "Speed: 2.0ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 2 drainages, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 drainages, 1 fault-manhole, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fault-manhole, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fault-manhole, 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 fault-manhole, 20.4ms\n",
      "Speed: 2.1ms preprocess, 20.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 fault-manhole, 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.4ms preprocess, 26.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 28.1ms\n",
      "Speed: 2.4ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.4ms preprocess, 26.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1303.5      584.44        1489      654.48           9           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:40.633333, Lat: 26.9150048, Lon: 75.7416909\n",
      "\n",
      "0: 384x640 1 crack, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1297.4      585.95      1480.4      657.56           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 27.9ms\n",
      "Speed: 1.4ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1303.2      581.69      1482.1      654.07           9           2]\n",
      "\n",
      "0: 384x640 3 cracks, 27.8ms\n",
      "Speed: 2.4ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1322.6       577.7      1487.6      646.67           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1327.6      570.27      1500.3      641.01           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[       1346      568.53      1528.6      642.23           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1362.6      569.37      1542.9       642.7           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 31.0ms\n",
      "Speed: 2.4ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1371.1       570.1        1554      643.23           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 28.6ms\n",
      "Speed: 1.5ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1380.3      572.07      1560.8      643.81           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1400.5      567.92      1576.5      641.66           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1397.7      559.21      1582.9      637.46           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 1 fault-manhole, 32.7ms\n",
      "Speed: 2.5ms preprocess, 32.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1396.1      551.44      1589.2      633.19           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 31.0ms\n",
      "Speed: 2.7ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 27.8ms\n",
      "Speed: 1.4ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 2 drainages, 1 fault-manhole, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1458.2      504.67      1674.9         597           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 57.0ms\n",
      "Speed: 5.8ms preprocess, 57.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[       1483      503.47      1699.2      594.96           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 29.5ms\n",
      "Speed: 1.5ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1498.9      505.92      1717.5      596.87           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1512.1      510.01      1728.8      601.91           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 1 drainage, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1530.9      519.45      1748.4      611.24           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 32.3ms\n",
      "Speed: 2.5ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1540.1      529.02      1763.5      622.05           9           2]\n",
      "\n",
      "0: 384x640 2 cracks, 1 drainage, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1561.4      537.58      1788.4      631.13           9           2]\n",
      "\n",
      "0: 384x640 1 crack, 32.7ms\n",
      "Speed: 2.5ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cracks, 29.9ms\n",
      "Speed: 2.2ms preprocess, 29.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1605.4      564.89      1813.1       656.3          16           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:41.400000, Lat: 26.9150048, Lon: 75.7416909\n",
      "\n",
      "0: 384x640 3 cracks, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1614.1      575.69      1844.5      668.87          16           2]\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 drainages, 32.2ms\n",
      "Speed: 1.6ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 29.6ms\n",
      "Speed: 2.5ms preprocess, 29.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 32.3ms\n",
      "Speed: 2.6ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 32.4ms\n",
      "Speed: 2.9ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 drainage, 29.3ms\n",
      "Speed: 2.7ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 1 pothole, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 2.4ms preprocess, 30.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.3ms preprocess, 27.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.4ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.5ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.7ms preprocess, 22.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.5ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 2.6ms preprocess, 27.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.9ms preprocess, 27.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 37.6ms\n",
      "Speed: 4.2ms preprocess, 37.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.7ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.5ms preprocess, 30.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.8ms preprocess, 28.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.4ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.8ms preprocess, 22.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.3ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.9ms\n",
      "Speed: 2.6ms preprocess, 27.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 26.5ms\n",
      "Speed: 2.2ms preprocess, 26.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.2ms\n",
      "Speed: 1.5ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 33.6ms\n",
      "Speed: 1.7ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.8ms\n",
      "Speed: 2.0ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     4.1986      237.35         637      417.96          23           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:44.900000, Lat: 26.9150048, Lon: 75.7416909\n",
      "\n",
      "0: 384x640 1 crack, 27.8ms\n",
      "Speed: 1.4ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1.9052      243.28      633.37      423.77          23           2]\n",
      "\n",
      "0: 384x640 1 crack, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 29.3ms\n",
      "Speed: 1.5ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cracks, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cracks, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     9.0205      446.94      338.82       559.8          26           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:45.333333, Lat: 26.9150048, Lon: 75.7416909\n",
      "\n",
      "0: 384x640 4 cracks, 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     4.5692      435.39      357.25         562          26           2]\n",
      "[    -22.968      379.53      358.06      557.16          25           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:45.366667, Lat: 26.9150048, Lon: 75.7416909\n",
      "\n",
      "0: 384x640 4 cracks, 30.5ms\n",
      "Speed: 8.8ms preprocess, 30.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 28.9ms\n",
      "Speed: 2.4ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1366.5      536.26      1517.4      636.12          28           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:45.433333, Lat: 26.9150048, Lon: 75.7416909\n",
      "\n",
      "0: 384x640 3 cracks, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1383.5      540.11      1539.2      641.75          28           2]\n",
      "\n",
      "0: 384x640 4 cracks, 24.1ms\n",
      "Speed: 2.3ms preprocess, 24.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1398.2       545.5      1553.2      645.22          28           2]\n",
      "\n",
      "0: 384x640 3 cracks, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1406.9      550.94      1562.5      649.95          28           2]\n",
      "\n",
      "0: 384x640 2 cracks, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1412.9      555.76      1572.3      654.39          28           2]\n",
      "\n",
      "0: 384x640 4 cracks, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1418.4      561.24      1578.8      659.93          28           2]\n",
      "\n",
      "0: 384x640 4 cracks, 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1420.1      562.55      1583.6      663.51          28           2]\n",
      "\n",
      "0: 384x640 4 cracks, 28.9ms\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     16.454      404.61      669.37      640.85          31           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:45.666667, Lat: 26.9150048, Lon: 75.7416909\n",
      "[       1419       565.5      1584.8      667.28          28           2]\n",
      "\n",
      "0: 384x640 2 cracks, 29.7ms\n",
      "Speed: 2.5ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     16.079      409.93      680.35      642.88          31           2]\n",
      "[     1415.3      566.85        1579      669.36          28           2]\n",
      "\n",
      "0: 384x640 3 cracks, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     12.459      414.53      673.65      640.22          31           2]\n",
      "[     1411.8      573.41      1576.3      676.35          28           2]\n",
      "\n",
      "0: 384x640 2 cracks, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     10.438      421.06      663.83       637.6          31           2]\n",
      "[     1409.4      578.88      1576.4      682.24          28           2]\n",
      "\n",
      "0: 384x640 3 cracks, 29.2ms\n",
      "Speed: 1.5ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -4.0036      423.67      646.85      650.74          31           2]\n",
      "[     1399.9      583.49      1570.1      687.48          28           2]\n",
      "\n",
      "0: 384x640 1 crack, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -8.0933      424.48       630.3      653.96          31           2]\n",
      "\n",
      "0: 384x640 3 cracks, 27.5ms\n",
      "Speed: 2.3ms preprocess, 27.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -9.7039      428.86      613.41       658.2          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     7.1407      441.19      611.97      658.86          31           2]\n",
      "\n",
      "0: 384x640 3 cracks, 26.7ms\n",
      "Speed: 1.4ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -18.498      458.78      525.82      665.86          31           2]\n",
      "\n",
      "0: 384x640 3 cracks, 26.7ms\n",
      "Speed: 2.4ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -20.979      463.58      487.39      671.26          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     -11.89      469.97      473.47      674.27          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     9.5111      476.78      507.69      680.55          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     12.919      473.56      523.74      685.71          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     11.413      478.07      523.62      690.13          31           2]\n",
      "\n",
      "0: 384x640 2 cracks, 26.8ms\n",
      "Speed: 1.4ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     12.208      486.69      525.69      699.68          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     10.043      489.99      522.53       706.2          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     6.1746      489.87      516.01      710.34          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.6ms\n",
      "Speed: 2.4ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1.5575      487.79      501.12      710.99          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      2.167      486.06      495.27      709.25          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     4.4637      486.02      492.51      706.41          31           2]\n",
      "\n",
      "0: 384x640 2 cracks, 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     10.835      489.86      505.78      713.67          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 22.3ms\n",
      "Speed: 1.4ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     9.7169       490.4      507.31      715.15          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.9ms\n",
      "Speed: 1.4ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     12.979      494.94      520.65      724.24          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     9.3739      495.25      519.52      725.61          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     7.0139      498.25      518.16      732.17          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 52.2ms\n",
      "Speed: 8.0ms preprocess, 52.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     4.8178      511.42      516.39      746.58          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     3.0929       508.4      512.74      747.41          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    0.78681      523.75      501.32      759.04          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[   -0.78549      531.63      489.93      766.35          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    0.35352       536.5      483.99      770.84          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1.1577      543.05      478.89      779.28          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.0ms\n",
      "Speed: 2.3ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     3.3673      550.29      481.06      791.11          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     9.7203      547.24       497.4      786.67          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     12.915      565.27      509.43      800.73          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     9.0592      589.02       513.2      837.15          31           2]\n",
      "\n",
      "0: 384x640 2 cracks, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      8.171      611.47         516      868.44          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.0ms\n",
      "Speed: 1.4ms preprocess, 27.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     3.1573      631.62      509.32      896.21          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -1.2558       649.2      501.46      920.96          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 25.4ms\n",
      "Speed: 1.3ms preprocess, 25.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -3.1961      655.97      490.28      918.42          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.7ms\n",
      "Speed: 1.3ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -5.6041      675.06      483.21      946.54          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -7.3711      682.81      473.64      956.62          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -12.258      684.52       454.1      955.67          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 28.5ms\n",
      "Speed: 2.3ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -15.751      688.46      433.46       956.5          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -14.933      695.78      420.43      962.72          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 28.3ms\n",
      "Speed: 1.4ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -13.823      714.53      407.75      978.49          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 29.0ms\n",
      "Speed: 1.4ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -18.108      724.89      383.75      988.42          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.1ms\n",
      "Speed: 2.4ms preprocess, 27.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -19.456      749.75       362.9      1009.1          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.5ms\n",
      "Speed: 2.3ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -25.654      779.57      330.98      1046.8          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.8ms\n",
      "Speed: 2.3ms preprocess, 26.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -30.404      797.25      294.88      1059.8          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -34.576      810.44      255.95      1064.6          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -36.708       827.9      218.12      1072.6          31           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[    -35.935       844.1      185.17      1079.6          31           2]\n",
      "\n",
      "0: 384x640 (no detections), 23.2ms\n",
      "Speed: 3.6ms preprocess, 23.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.2ms\n",
      "Speed: 3.5ms preprocess, 35.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.4ms preprocess, 25.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.4ms preprocess, 25.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.4ms preprocess, 25.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 2.3ms preprocess, 28.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 3.7ms preprocess, 29.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 drainages, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 drainages, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 27.0ms\n",
      "Speed: 1.4ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 26.4ms\n",
      "Speed: 1.3ms preprocess, 26.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 26.8ms\n",
      "Speed: 1.4ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 28.0ms\n",
      "Speed: 1.4ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 27.0ms\n",
      "Speed: 1.4ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.3ms preprocess, 25.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 39.8ms\n",
      "Speed: 5.5ms preprocess, 39.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.2ms\n",
      "Speed: 2.3ms preprocess, 25.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.4ms preprocess, 25.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.5ms\n",
      "Speed: 2.1ms preprocess, 24.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.4ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.4ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 25.7ms\n",
      "Speed: 1.4ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 drainages, 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 27.5ms\n",
      "Speed: 2.4ms preprocess, 27.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 25.7ms\n",
      "Speed: 1.4ms preprocess, 25.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.7ms\n",
      "Speed: 2.2ms preprocess, 31.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.3ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.4ms\n",
      "Speed: 2.5ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.4ms preprocess, 25.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 broken-dividers, 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.7ms\n",
      "Speed: 1.4ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.3ms\n",
      "Speed: 2.3ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 25.5ms\n",
      "Speed: 2.3ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.5ms\n",
      "Speed: 2.5ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 29.5ms\n",
      "Speed: 2.8ms preprocess, 29.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     977.17      357.11      1061.2      481.04          43           0]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:49.900000, Lat: 26.9150825, Lon: 75.7416004\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     977.03      357.54      1058.8      481.87          43           0]\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     968.72      363.08      1051.3      489.72          43           0]\n",
      "\n",
      "0: 384x640 3 broken-dividers, 35.7ms\n",
      "Speed: 1.5ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     965.26      357.82      1051.3      490.26          43           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 34.4ms\n",
      "Speed: 2.7ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.5ms\n",
      "Speed: 1.6ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 broken-dividers, 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     921.03      383.46      1006.6      520.65          43           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.2ms\n",
      "Speed: 1.4ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 broken-dividers, 29.1ms\n",
      "Speed: 2.4ms preprocess, 29.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 30.1ms\n",
      "Speed: 1.8ms preprocess, 30.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 broken-dividers, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.6ms\n",
      "Speed: 2.1ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1022.9       313.6      1103.6      432.82          51           0]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:50.533333, Lat: 26.9150825, Lon: 75.7416004\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[       1030       317.6      1107.5      435.25          51           0]\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.3ms\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1029.9      323.56        1108       439.8          51           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.0ms\n",
      "Speed: 1.4ms preprocess, 29.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1023.9      342.14      1098.8      457.76          51           0]\n",
      "\n",
      "0: 384x640 3 broken-dividers, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 26.9ms\n",
      "Speed: 2.0ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.4ms\n",
      "Speed: 2.1ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 broken-dividers, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.1ms\n",
      "Speed: 1.4ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.2ms\n",
      "Speed: 1.4ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 27.7ms\n",
      "Speed: 2.2ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.3ms\n",
      "Speed: 1.3ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.1ms\n",
      "Speed: 1.4ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1117.9      368.12      1226.6      471.57          59           0]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:51.133333, Lat: 26.9150825, Lon: 75.7416004\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 broken_road_side, 28.0ms\n",
      "Speed: 1.4ms preprocess, 28.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.4ms preprocess, 27.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 broken_road_side, 27.8ms\n",
      "Speed: 1.5ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 drainage, 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.7ms\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 1 drainage, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 broken-dividers, 1 drainage, 24.5ms\n",
      "Speed: 2.3ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.9ms\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1005.4      356.74      1104.1      464.37          65           0]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:51.533333, Lat: 26.9150825, Lon: 75.7416004\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     980.36      357.82      1081.4      467.55          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[      951.4      352.84      1061.4      469.44          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     945.36      353.01      1053.4      467.51          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     925.63      354.79      1036.4      470.02          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     918.98      355.25      1027.3      469.76          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     906.88      355.49      1016.6      470.93          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 26.8ms\n",
      "Speed: 1.4ms preprocess, 26.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     897.28      354.85      1007.7      470.74          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     890.39      353.76      1002.8      470.17          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 22.8ms\n",
      "Speed: 2.1ms preprocess, 22.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     879.66      353.63      991.51      470.34          65           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     866.22      355.05      975.14      471.59          65           0]\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.4ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.9ms\n",
      "Speed: 4.7ms preprocess, 30.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 24.9ms\n",
      "Speed: 1.5ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.7ms\n",
      "Speed: 2.3ms preprocess, 28.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.1ms preprocess, 27.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.5ms preprocess, 24.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 22.3ms\n",
      "Speed: 2.1ms preprocess, 22.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.4ms preprocess, 27.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 30.7ms\n",
      "Speed: 3.1ms preprocess, 30.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.3ms preprocess, 25.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 crack, 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.4ms preprocess, 29.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.6ms preprocess, 30.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.5ms preprocess, 27.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 2.7ms preprocess, 29.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 24.9ms\n",
      "Speed: 2.3ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.9ms\n",
      "Speed: 2.2ms preprocess, 23.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.3ms preprocess, 26.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.0ms\n",
      "Speed: 1.5ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.3ms\n",
      "Speed: 1.4ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.4ms preprocess, 27.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.2ms\n",
      "Speed: 3.5ms preprocess, 43.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.4ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 26.3ms\n",
      "Speed: 3.4ms preprocess, 26.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.2ms\n",
      "Speed: 2.1ms preprocess, 25.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.4ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 20.7ms\n",
      "Speed: 2.0ms preprocess, 20.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.5ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.1ms preprocess, 28.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.5ms preprocess, 26.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.1ms\n",
      "Speed: 1.3ms preprocess, 21.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 2.2ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.4ms preprocess, 27.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.5ms preprocess, 28.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.4ms preprocess, 28.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.5ms preprocess, 27.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.4ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 3.4ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.7ms\n",
      "Speed: 2.2ms preprocess, 22.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.8ms preprocess, 22.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.9ms\n",
      "Speed: 2.0ms preprocess, 21.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.4ms preprocess, 22.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 20.6ms\n",
      "Speed: 1.7ms preprocess, 20.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.4ms preprocess, 27.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 2.7ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.8ms preprocess, 32.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.7ms preprocess, 32.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.4ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.2ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.3ms preprocess, 29.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.3ms preprocess, 29.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.2ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.2ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 2.7ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.4ms preprocess, 28.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.1ms preprocess, 30.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.1ms preprocess, 27.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 26.6ms\n",
      "Speed: 2.2ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.3ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.4ms preprocess, 24.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 35.8ms\n",
      "Speed: 2.7ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.4ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 26.6ms\n",
      "Speed: 1.4ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cracks, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.7ms\n",
      "Speed: 1.4ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 29.5ms\n",
      "Speed: 2.3ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1725.2      318.74      1807.1      380.45          73           2]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:06:57, Lat: 26.9150328, Lon: 75.7418061\n",
      "\n",
      "0: 384x640 1 crack, 30.8ms\n",
      "Speed: 2.5ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[       1717      332.97      1801.6      397.16          73           2]\n",
      "\n",
      "0: 384x640 1 crack, 31.0ms\n",
      "Speed: 2.4ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1706.5      342.12      1796.7      409.58          73           2]\n",
      "\n",
      "0: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.8ms\n",
      "Speed: 1.5ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 crack, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1689.1       397.6        1787      469.14          73           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1710.9      414.02      1811.3      483.74          73           2]\n",
      "\n",
      "0: 384x640 1 crack, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1723.1      431.76      1826.5       505.1          73           2]\n",
      "\n",
      "0: 384x640 1 crack, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.4ms preprocess, 27.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.4ms preprocess, 27.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.8ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.3ms preprocess, 26.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.3ms preprocess, 27.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.0ms\n",
      "Speed: 2.1ms preprocess, 22.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.4ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.3ms preprocess, 31.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.4ms preprocess, 31.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.1ms\n",
      "Speed: 2.6ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 pothole, 28.1ms\n",
      "Speed: 2.3ms preprocess, 28.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 pothole, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 drainage, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.4ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.4ms preprocess, 24.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.4ms\n",
      "Speed: 2.3ms preprocess, 24.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.4ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.7ms preprocess, 29.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 30.3ms\n",
      "Speed: 3.6ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.4ms preprocess, 23.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.4ms preprocess, 24.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 4.3ms preprocess, 26.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.3ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 2.2ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.4ms preprocess, 26.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.4ms preprocess, 27.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 34.9ms\n",
      "Speed: 8.4ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 33.1ms\n",
      "Speed: 2.4ms preprocess, 33.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.6ms preprocess, 31.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.5ms preprocess, 27.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 broken-dividers, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 26.8ms\n",
      "Speed: 1.4ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.5ms preprocess, 27.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.4ms preprocess, 26.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.9ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 22.8ms\n",
      "Speed: 2.6ms preprocess, 22.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.4ms preprocess, 28.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 35.0ms\n",
      "Speed: 3.7ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.3ms\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.7ms\n",
      "Speed: 1.4ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.3ms\n",
      "Speed: 1.5ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 broken_road_side, 32.6ms\n",
      "Speed: 1.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.8ms\n",
      "Speed: 1.4ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.6ms\n",
      "Speed: 1.5ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1301.1      285.35      1379.7      354.13          83           0]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:07:00.700000, Lat: 26.9149523, Lon: 75.7418846\n",
      "\n",
      "0: 384x640 2 broken-dividers, 28.9ms\n",
      "Speed: 1.3ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1285.3      283.81      1382.6       362.3          83           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 50.1ms\n",
      "Speed: 13.3ms preprocess, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1274.6      289.93      1367.7      367.74          83           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 29.5ms\n",
      "Speed: 1.5ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 37.8ms\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.1ms\n",
      "Speed: 2.4ms preprocess, 31.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 29.6ms\n",
      "Speed: 2.2ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[       1165      321.33      1236.9      403.12          84           0]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:07:01.066667, Lat: 26.9149523, Lon: 75.7418846\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1149.4      327.01      1216.5      403.76          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1132.9      329.61      1202.5      408.61          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 31.1ms\n",
      "Speed: 2.5ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1120.9      331.64      1190.2      410.83          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 31.6ms\n",
      "Speed: 2.7ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1102.7      332.97      1175.6       414.8          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 36.8ms\n",
      "Speed: 1.9ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1084.5      335.66      1159.3      419.88          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1064.5      344.78      1137.5      426.18          84           0]\n",
      "\n",
      "0: 384x640 2 broken-dividers, 1 pothole, 33.5ms\n",
      "Speed: 2.0ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1051.8      351.43        1122      430.98          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 2 potholes, 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1032.5      358.47      1105.4      439.22          84           0]\n",
      "\n",
      "0: 384x640 2 broken-dividers, 2 potholes, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     1013.5      362.98      1085.7      442.73          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 42.6ms\n",
      "Speed: 1.8ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     683.73      340.37      832.97      401.23          86           5]\n",
      "Data successfully appended to /home/annone/ai/survey/temp_database_test.json\n",
      "Detection Time: 2024-11-19 15:07:01.400000, Lat: 26.9149523, Lon: 75.7418846\n",
      "[     991.57      366.48      1064.4      447.85          84           0]\n",
      "\n",
      "0: 384x640 2 broken-dividers, 1 pothole, 30.3ms\n",
      "Speed: 4.7ms preprocess, 30.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     671.34      343.99      818.89      403.93          86           5]\n",
      "[     976.43       371.1      1048.1      452.74          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 1 pothole, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     650.89      353.67      799.85      411.44          86           5]\n",
      "[      959.7      376.19      1031.8      458.82          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 3 potholes, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     610.13      353.61      774.96      414.04          86           5]\n",
      "[     941.84       380.9      1012.7      464.57          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 31.8ms\n",
      "Speed: 4.4ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     911.23      388.83      987.18       473.4          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     887.41      397.17      963.42      482.21          84           0]\n",
      "\n",
      "0: 384x640 2 broken-dividers, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     860.27      405.01      940.38      492.97          84           0]\n",
      "\n",
      "0: 384x640 1 broken-divider, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[     831.47      412.78       912.8      500.38          84           0]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m frame_time \u001b[38;5;241m=\u001b[39m initial_time \u001b[38;5;241m+\u001b[39m timedelta(seconds\u001b[38;5;241m=\u001b[39mframe_index \u001b[38;5;241m/\u001b[39m fps)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Run the model on the current frame\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m class_list \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnames\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Prepare detections for SORT (format: [x1, y1, x2, y2, confidence])\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/engine/model.py:176\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    149\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/engine/model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/nn/autobackend.py:461\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 461\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/nn/tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/nn/modules/head.py:64\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_end2end(x)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[0;32m---> 64\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2[i](x[i]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Extract the file's modified time as the initial time\n",
    "file_modified_time = os.path.getmtime(input_video_path)\n",
    "initial_time = datetime.fromtimestamp(file_modified_time)\n",
    "# Read the coordinates from the file\n",
    "coordinates = []\n",
    "with open('/home/annone/ai/survey/coordinates_with_timestamp.txt', 'r') as f:  # Replace with the path to your file\n",
    "    for line in f:\n",
    "        lat, lon,time_str = [i.split(\": \")[1] for i in line.strip().split(',')]\n",
    "        coordinates.append({\n",
    "            \"timestamp\": datetime.strptime(time_str, \"%Y-%m-%d %H:%M:%S.%f\"),\n",
    "            \"latitude\": float(lat),\n",
    "            \"longitude\": float(lon)\n",
    "        })\n",
    "\n",
    "# Open the input video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get the video's width, height, FPS, and frame count\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' for .avi output\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Initialize the SORT tracker\n",
    "tracker = Sort()\n",
    "known_track_id = []\n",
    "# Process the video frame by frame\n",
    "frame_index = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Calculate the current frame's timestamp\n",
    "    frame_time = initial_time + timedelta(seconds=frame_index / fps)\n",
    "\n",
    "    # Run the model on the current frame\n",
    "    results = model(frame)\n",
    "    class_list = model.names\n",
    "    # Prepare detections for SORT (format: [x1, y1, x2, y2, confidence])\n",
    "    detections = []\n",
    "    for detection in results[0].boxes:\n",
    "        confidence = detection.conf.item()  # Confidence score\n",
    "        class_id = int(detection.cls.item())  # Class ID\n",
    "        class_name = model.names[class_id]  # Class name\n",
    "\n",
    "        # Skip detections below 30% confidence or class \"drainage\"\n",
    "        if confidence < 0.3 or class_name == \"drainage\":\n",
    "            continue\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        x1, y1, x2, y2 = map(int, detection.xyxy[0])  # Convert to integers\n",
    "        detections.append([x1, y1, x2, y2, confidence,class_id])\n",
    "\n",
    "    # Convert detections to NumPy array\n",
    "    detections = np.array(detections)\n",
    "\n",
    "    # Ensure detections array has the correct shape (N, 5)\n",
    "    if len(detections) == 0:\n",
    "        detections = np.empty((0, 6))  # Empty array with the correct shape\n",
    "\n",
    "    # Update the SORT tracker with the current frame's detections\n",
    "    tracked_objects = tracker.update(detections)\n",
    "\n",
    "    # Create a copy of the frame for annotation\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    # Loop through the tracked objects\n",
    "    for obj in tracked_objects:\n",
    "        print(obj)\n",
    "        # Format: [x1, y1, x2, y2, track_id]\n",
    "        x1, y1, x2, y2, track_id, class_id = map(int, obj[:6])\n",
    "\n",
    "        # Draw the bounding box and track ID\n",
    "        label = f\"ID {track_id}\"\n",
    "        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(annotated_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        # Find the nearest timestamp in the coordinates file\n",
    "        nearest_coord = min(coordinates, key=lambda coord: abs(coord[\"timestamp\"] - frame_time))\n",
    "        lat, lon = nearest_coord[\"latitude\"], nearest_coord[\"longitude\"]\n",
    "\n",
    "        # Print the coordinates and lat/lon\n",
    "        if track_id not in known_track_id:\n",
    "            # time.sleep(2)\n",
    "            with open(\"/home/annone/ai/survey/output.txt\", \"a\") as outfile:\n",
    "                outfile.write(f\"Class: {class_id}, Detection Time: {frame_time}, Lat: {lat}, Lon: {lon}, trackid : {track_id}\\n\")\n",
    "                # save_to_postgres(\n",
    "                #     thumbnail=f\"{track_id}.jpg\",\n",
    "                #     class_name=f\"{class_list[class_id]}\",\n",
    "                #     geo_coords=json.dumps([lat,lon]),  # Example list of coordinates\n",
    "                #     survey_id=\"1\",\n",
    "                #     distance=\"100\"\n",
    "                # )\n",
    "                json_data = {\n",
    "                    \"detection_id\":f\"{uuid.uuid4()}\",\n",
    "                    \"thumbnail\": f\"{track_id}.jpg\",\n",
    "                    \"class_name\": f\"{class_list[class_id]}\",\n",
    "                    \"location\": [lat,lon],\n",
    "                    \"survey_id\": \"1\",\n",
    "                    \"distance\": \"100\",\n",
    "                    \"track_id\": f\"{track_id}\"\n",
    "                }\n",
    "                log_into_json(json_data_file, json_data)\n",
    "            cv2.imwrite(f\"/home/annone/ai/survey/static/images/{track_id}.jpg\",annotated_frame)\n",
    "            print(f\"Detection Time: {frame_time}, Lat: {lat}, Lon: {lon}\")\n",
    "            known_track_id.append(track_id)\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Increment the frame index\n",
    "    frame_index += 1\n",
    "\n",
    "    # Display the frame (optional)\n",
    "    # cv2.imshow('Object Tracking', annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "Database.return_connection(connection=conn)\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import uvicorn\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sort.sort import Sort\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load the YOLO model\n",
    "MODEL_PATH = '/home/annone/ai/survey/data/weights/best.pt'  # Update path\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# JSON data file\n",
    "JSON_DATA_FILE = \"/home/annone/ai/survey/temp_database.json\"\n",
    "COORDINATES_FILE = '/home/annone/ai/survey/coordinates_with_timestamp.txt'\n",
    "OUTPUT_IMAGE_DIR = \"/home/annone/ai/survey/static/images/\"\n",
    "os.makedirs(OUTPUT_IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "# Helper: Read and write to JSON file\n",
    "def log_into_json(file_path, data):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            existing_data = json.load(f)\n",
    "    else:\n",
    "        existing_data = []\n",
    "\n",
    "    existing_data.append(data)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "# Helper: Load coordinates with timestamps\n",
    "def load_coordinates():\n",
    "    coordinates = []\n",
    "    with open(COORDINATES_FILE, 'r') as f:\n",
    "        for line in f:\n",
    "            lat, lon, time_str = [i.split(\": \")[1] for i in line.strip().split(',')]\n",
    "            coordinates.append({\n",
    "                \"timestamp\": datetime.strptime(time_str, \"%Y-%m-%d %H:%M:%S.%f\"),\n",
    "                \"latitude\": float(lat),\n",
    "                \"longitude\": float(lon)\n",
    "            })\n",
    "    return coordinates\n",
    "\n",
    "# Route to process video\n",
    "@app.post(\"/process-video/\")\n",
    "async def process_video(video: UploadFile = File(...)):\n",
    "    # Save uploaded video to a temporary location\n",
    "    input_video_path = f\"/tmp/{video.filename}\"\n",
    "    output_video_path = input_video_path.replace(\".mp4\", \"_processed.mp4\")\n",
    "\n",
    "    try:\n",
    "        with open(input_video_path, \"wb\") as buffer:\n",
    "            buffer.write(await video.read())\n",
    "\n",
    "        # Extract file modified time\n",
    "        file_modified_time = os.path.getmtime(input_video_path)\n",
    "        initial_time = datetime.fromtimestamp(file_modified_time)\n",
    "\n",
    "        # Load coordinates\n",
    "        coordinates = load_coordinates()\n",
    "\n",
    "        # Open video file\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "        # Get video properties\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        # Initialize SORT tracker\n",
    "        tracker = Sort()\n",
    "        known_track_id = []\n",
    "        frame_index = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Calculate frame timestamp\n",
    "            frame_time = initial_time + timedelta(seconds=frame_index / fps)\n",
    "\n",
    "            # Run YOLO model\n",
    "            results = model(frame)\n",
    "            class_list = model.names\n",
    "\n",
    "            # Prepare detections for SORT\n",
    "            detections = []\n",
    "            for detection in results[0].boxes:\n",
    "                confidence = detection.conf.item()\n",
    "                class_id = int(detection.cls.item())\n",
    "                class_name = model.names[class_id]\n",
    "\n",
    "                if confidence < 0.3 or class_name == \"drainage\":\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, detection.xyxy[0])\n",
    "                detections.append([x1, y1, x2, y2, confidence, class_id])\n",
    "\n",
    "            detections = np.array(detections) if len(detections) > 0 else np.empty((0, 6))\n",
    "\n",
    "            # Update tracker\n",
    "            tracked_objects = tracker.update(detections)\n",
    "\n",
    "            # Annotate frame\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            for obj in tracked_objects:\n",
    "                x1, y1, x2, y2, track_id, class_id = map(int, obj[:6])\n",
    "                label = f\"ID {track_id}\"\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(annotated_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "                nearest_coord = min(coordinates, key=lambda coord: abs(coord[\"timestamp\"] - frame_time))\n",
    "                lat, lon = nearest_coord[\"latitude\"], nearest_coord[\"longitude\"]\n",
    "\n",
    "                if track_id not in known_track_id:\n",
    "                    json_data = {\n",
    "                        \"detection_id\": str(uuid.uuid4()),\n",
    "                        \"thumbnail\": f\"{track_id}.jpg\",\n",
    "                        \"class_name\": f\"{class_list[class_id]}\",\n",
    "                        \"location\": [lat, lon],\n",
    "                        \"survey_id\": \"1\",\n",
    "                        \"distance\": \"100\",\n",
    "                        \"track_id\": str(track_id)\n",
    "                    }\n",
    "                    log_into_json(JSON_DATA_FILE, json_data)\n",
    "                    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, f\"{track_id}.jpg\"), annotated_frame)\n",
    "                    known_track_id.append(track_id)\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            frame_index += 1\n",
    "\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        return JSONResponse(content={\"message\": \"Video processed successfully\", \"output_video\": output_video_path})\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"An error occurred: {str(e)}\")\n",
    "\n",
    "    finally:\n",
    "        if os.path.exists(input_video_path):\n",
    "            os.remove(input_video_path)\n",
    "\n",
    "# Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
